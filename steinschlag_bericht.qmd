---
title: "Bericht Steinschlagrisiko"
subtitle: "Challenge CWM1"
author: "Livio Prosdocimo, Roberto Lorusso, Linus Ackermann"
date: last-modified
date-format: "DD.MM.YYYY"
format: pdf
toc: true
toc-title: "Inhaltsverzeichnis"
echo: false
---

```{r}
library(ggplot2)
```

\newpage

# Problem

\newpage

# Wahrscheinlichkeitsmodellierung
## Zufallsvariablen 
## 

## Verteilungen

Da Steinschläge über einen Zeitraum von drei Monaten aufgrund der begrenzten Anzahl an Ereignissen keine verlässlichen Aussagen über die aktuelle Gefahr ermöglichen, müssen Fälle nachgestellt werden. Um eine solche Simulation korrekt durchzuführen, werden die vorhandenen Daten der Steinschläge in die drei oben genannten Variablen Masse, Geschwindigkeit und zeitliche Abstände unterteilt.

Dann können diese Daten anhand ihren Eigenschaften simuliert werden. Dafür wird für jede Kategorie eine Wahrscheinlichkeitsverteilung zugeordnet. Durch die Zuordnung können die Eigenschaften der Daten anhand einem theoretisches Modell widerspiegelt werden und Fälle nachstellen, die der Vergangenheit am nächsten kommen.

### Verteilungen Zone 1

```{r, echo = FALSE}

library(tidyverse)
library(fitdistrplus)
library(univariateML)
library(MASS)

# Read Data
zone_raw_1 <- read.csv("resources/out_1.csv")

# Data Wrangling
zone_1 <- zone_raw_1 %>% 
  filter(Datum != "",) %>% 
  mutate(
    datetime = ymd_hm(paste(Datum, Uhrzeit, sep = " ")), 
    masse = Masse..kg., 
    velocity = Geschwindigkeit..m.s.) %>% 
  arrange(datetime) %>% 
  filter(masse > 0) %>% 
  dplyr::select(datetime, masse, velocity)


# Data Wrangling for Time Difference
time_diff_1 <- data.frame(
  stunden = as.numeric(diff(zone_1$datetime))
  ) %>% 
  mutate(stunden = stunden /60/60) # Um stunden zu erhalten
```

### Zone 1 Masse

Zunächst wird der Hang 1 hinsichtlich der Masse untersucht.

Zuerst werden  mit dem fitdistr-Package verschiedene Verteilungen auf den Datensatz der Masse angewendet um diese dann zu analysieren. 

Alle Verteilungen werden dann mit einem Histogramm welches die Daten wiederspiegelt angezeigt. In einem zweiten Plot, der ein Cullen-Frey-Diagramm darstellt, werden die Datenpunkte zusammen mit den Verteilungen verglichen. Die Verteilungen, die am nächsten an den Beobachtungspunkten liegen, sind tendenziell kompatibler.

Diese beiden Vergleiche allein erlauben noch keine endgültige Entscheidung darüber, welche Verteilung am besten geeignet ist. Sie dienen jedoch dazu, die Auswahl der möglichen Verteilungen einzuschränken und eine Orientierung zu geben, mit welchen Daten gearbeitet wird. 

Dabei zeigt sich, dass nur die Weibull- und die Lognormalverteilung in Frage kommen könnten.


```{r, echo = FALSE}
# Calc Distribution
mass.norm_1 <- fitdist(zone_1$masse, "norm")
mass.unif_1 <- fitdist(zone_1$masse, "unif")
mass.lnorm_1 <- fitdist(zone_1$masse, "lnorm")
mass.weibull_1 <- fitdist(zone_1$masse, "weibull")
mass.legend_1 <- c("Normal", "Unif", "Lognormal","Weibull")
```

```{r, echo = FALSE}
# Plot different Distributions for mass
denscomp(list(mass.norm_1, mass.unif_1, mass.lnorm_1, mass.weibull_1), legendtext = mass.legend_1, plotstyle = "ggplot")
descdist(zone_1$mass, boot = 10000, discrete = FALSE)
```

Diese werden in einem Goodness-of-Fit-Test verglichen. Dazu müssen die CDF-, QQ- und PP-Plots betrachtet werden. Die Punkte in den Plots stellen den Vergleich der vorhandenen Daten auf der Y-Achse dar, im Vergleich zu den theoretischen Werten auf der X Achse, welche die Verteilung erzeugt. 

Der QQ-Plot vergleicht die Quantile, der PP-Plot die Perzentile und der CDF-Plot die kumulative Verteilungsfunktion.
Wie gut eine Verteilung zu den Daten passt, erkennt man an den Linien. Wenn die Punkte der Gegenüberstellung auf der Linie liegen, passt die Verteilung gut zu den Daten.

Mit der Funktion UnivariateML können verschiedene Verteilungen bereits im Vorhinein getestet werden, um herauszufinden, welche am besten zu den Daten passt. Diese Funktion vergleicht die Kompatibilität der Daten mit verschiedenen Verteilungen und bietet somit eine Möglichkeit, eine mögliche Passform für die vorliegenden Daten zu ermitteln. Diese Funktion unterstützt die Auswahl von Verteilungen 

In diesem Fall wird die Lognormalverteilung empfohlen.

```{r, echo = FALSE}
# Die passen am besten
plot(mass.lnorm_1)
plot(mass.unif_1)
plot(mass.weibull_1)
plot(mass.norm_1)

model_select(zone_1$masse)#lognormal  besser
```

Vergleicht man die Masse am Hang 1 zwischen der Lognormalverteilung und der Weibullverteilung, so liegt die Lognormalverteilung nahe an der Linie, nur das letzte Quantil im QQ-Plot weicht deutlich ab. Bei der Weibullverteilung weichen die Punkte ebenfalls von der Linie ab, aber insbesondere das letzte Quantil liegt nahe an der Linie.

Trotz kleiner Abweichungen wird die Weibull-Verteilung gewählt. Größere Massen bedeuten ein höheres Risiko, daher ist es wichtiger, die schwersten Massen mit der Verteilung abzudecken.

Dieser Vorgang wird für die Auswahl bei allen Variablen wiederholt.

### Zone 1 Geschwindigkeit

Durch die erste Analyse stellt sich heraus, dass viele Verteilungen passen könnten, Normalverteilung, Weibull, Exponential, Gamma oder Lognormal. 

Der Vorschlag von UnivariateML ist die Normalverteilung.

```{r, echo = FALSE}
# Calc Distribution
velocity.norm_1 <- fitdist(zone_1$velocity, "norm")
velocity.expo_1 <- fitdist(zone_1$velocity, "exp")
velocity.unif_1 <- fitdist(zone_1$velocity, "unif")
velocity.lnorm_1 <- fitdist(zone_1$velocity, "lnorm")
velocity.gamm_1 <- fitdist(zone_1$velocity, "gamma")
velocity.weibull_1 <- fitdist(zone_1$velocity, "weibull")
velocity.legend_1 <- c("Normal", "Exponential", "Unif", "Lognormal", "Gamma", "Weibull")
```

```{r, echo = FALSE}
# Plot different Distributions for velocity
denscomp(list(velocity.norm_1, velocity.expo_1, velocity.unif_1, velocity.lnorm_1, velocity.gamm_1, velocity.weibull_1), legendtext = velocity.legend_1, plotstyle = "ggplot")
descdist(zone_1$velocity, boot = 10000, discrete = FALSE)
```

```{r, echo = FALSE}
# Die passen am besten
plot(velocity.norm_1)
plot(velocity.weibull_1)
plot(velocity.expo_1)
plot(velocity.gamm_1)
plot(velocity.lnorm_1)

model_select(zone_1$velocity)#Normalverteilung passt am besten
```

Nach dem Abgleich der Plots ist klar, dass die Normalverteilung am genauesten passt. Die Punkte verlaufen fast durchgehend entlang der Linie, was auf eine gute Übereinstimmung mit den Daten hinweist. Besonders in den oberen Quantilen ist diese Verteilung am nächsten bei der Linie.

### Zone 1 Zeitabstände

Die erste Analyse deutet in diesem Fall klar darauf hin, dass nur eine Exponential- oder Normalverteilung passend sein könnten. Der Vorschlag von UnivariateML ist die Exponentialverteilung.

```{r, echo = FALSE}
# Calc Distribution
time_diff.norm_1 <- fitdist(time_diff_1$stunden, "norm")
time_diff.unif_1 <- fitdist(time_diff_1$stunden, "unif")
time_diff.expo_1 <- fitdist(time_diff_1$stunden, "exp")
time_diff.legend_1 <- c("Normal", "Unif", "Expo")
```

```{r, echo = FALSE}
# Plot different Distributions for velocity
denscomp(list(time_diff.norm_1, time_diff.unif_1, time_diff.expo_1), legendtext = time_diff.legend_1, plotstyle = "ggplot")
descdist(time_diff_1$stunden, boot = 10000)
```

```{r, echo = FALSE}
# Die passen am besten 
plot(time_diff.norm_1)
plot(time_diff.unif_1)
plot(time_diff.expo_1)


model_select(time_diff_1$stunden)#exponentiell model
```

Die Auswertung der Plots zeigt deutlich, dass die Exponentialverteilung am besten passt.

Die kleineren Quantile werden bei der Exponentialverteilung besser gedeckt. Bei den Zeitlichen Abstände sind die kleineren Quantile wichtiger, da weniger Zeitintervalle mehrere Steinschläge bedeuten und somit eine größere Gefahr darstellen.

```{r, echo = FALSE}
# Read Data
zone_raw <- read.csv("resources/out_2.csv")

# Data Wrangling
zone <- zone_raw %>% 
  filter(Date != "",) %>% 
  mutate(
    datetime = ymd_hm(paste(Date, Uhrzeit, sep = " ")), 
    masse = m..kg., 
    velocity = v..m.s.) %>% 
  arrange(datetime) %>% 
  filter(masse > 0) %>% 
  dplyr::select(datetime, masse, velocity)

# Data Wrangling for Time Difference
time_diff <- data.frame(
  stunden = as.numeric(diff(zone$datetime)))
```

### Verteilungen Zone 2
### Zone 2 Masse

Nach einer ersten Prüfung bleiben die Verteilungen Weibull, Gamma, Exponential und Lognormal zur Auswahl. Der Vorschlag von UnivariateML ist die Exponentialverteilung.

```{r, echo = FALSE}
# Calc Distribution
mass.norm <- fitdist(zone$masse, "norm")
mass.expo <- fitdist(zone$masse, "exp")
mass.unif <- fitdist(zone$masse, "unif")
mass.lnorm <- fitdist(zone$masse, "lnorm")
mass.gamm <- fitdist(zone$masse, "gamma")
mass.weibull <- fitdist(zone$masse, "weibull")
mass.legend <- c("Normal", "Exponential", "Unif", "Lognormal", "Gamma", "Weibull")

```


```{r, echo = FALSE}
# Plot different Distributions for mass
denscomp(list(mass.norm, mass.expo, mass.unif, mass.lnorm, mass.gamm, mass.weibull), legendtext = mass.legend, plotstyle = "ggplot")
descdist(zone$mass, boot = 10000, discrete = FALSE)
```


```{r, echo = FALSE}
# Die passen am besten 
plot(mass.expo)
plot(mass.gamm)
plot(mass.weibull)
plot(mass.lnorm)

model_select(zone$masse) 
```

Nach Bewertung der Plots wird die Exponentialverteilung gewählt. Gamma, Weibull sind ähnlich wie die Exponentialverteilung, decken aber die oberen Quantile schlechter ab. Lognormal liegt im Allgemeinen näher an der Linie, lässt aber das letzte Quantil aus. Auch am zweiten Hang ist die größere Masse ausschlaggebender.

### Zone 2 Geschwindigkeit

Die Diagramme zeigen, dass viele Verteilungen ausgewählt werden können. Normal, Lognormal, Weibull und Gamma stehen zur Auswahl.

Der Vorschlag von UnivariateML ist die Weibullverteilung.

```{r, echo = FALSE}
# Calc Distribution
velocity.norm <- fitdist(zone$velocity, "norm")
velocity.expo <- fitdist(zone$velocity, "exp")
velocity.unif <- fitdist(zone$velocity, "unif")
velocity.lnorm <- fitdist(zone$velocity, "lnorm")
velocity.gamm <- fitdist(zone$velocity, "gamma")
velocity.weibull <- fitdist(zone$velocity, "weibull")
velocity.legend <- c("Normal", "Exponential", "Unif", "Lognormal", "Gamma", "Weibull")
```


```{r, echo = FALSE}
# Plot different Distributions for velocity
denscomp(list(velocity.norm, velocity.expo, velocity.unif, velocity.lnorm, velocity.gamm, velocity.weibull), legendtext = velocity.legend, plotstyle = "ggplot")
descdist(zone$velocity, boot = 10000, discrete = FALSE)
```


```{r, echo = FALSE}
# Die passen am besten
plot(velocity.norm)
plot(velocity.lnorm)
plot(velocity.gamm)
plot(velocity.weibull)

#Check
model_select(zone$velocity)#Weibull passt am besten
```

Die Auswertung zeigt, dass nur die Weibullverteilung die Daten umfangreich decken kann. Daher wird diese Verteilung gewählt.

### Zone 2 Zeitabstände

In diesem Fall erkennt man ebenfalls, dass die Verteilungen Weibull, Gamma, Exponential und Lognormal zur Auswahl stehen. 
Der Vorschlag von UnivariateML ist die Gammaverteilung

```{r, echo = FALSE}
# Calc Distribution
time_diff.norm <- fitdist(time_diff$stunden, "norm")
time_diff.expo <- fitdist(time_diff$stunden, "exp")
time_diff.unif <- fitdist(time_diff$stunden, "unif")
time_diff.lnorm <- fitdist(time_diff$stunden, "lnorm")
time_diff.gamm <- fitdist(time_diff$stunden, "gamma")
time_diff.weibull <- fitdist(time_diff$stunden, "weibull")
time_diff.legend <- c("Normal", "Exponential", "Unif", "Lognormal", "Gamma", "Weibull")
```


```{r, echo = FALSE}
# Plot different Distributions for time difference

denscomp(list(time_diff.norm, time_diff.expo, time_diff.unif, time_diff.lnorm, time_diff.gamm, time_diff.weibull), legendtext = time_diff.legend, plotstyle = "ggplot")
descdist(time_diff$stunden, boot = 10000)
```



```{r, echo = FALSE}
# Die passen am besten 
plot(time_diff.lnorm)
plot(time_diff.gamm)
plot(time_diff.weibull)
plot(time_diff.expo)

#Check
model_select(time_diff$stunden)#gamma passt am besten
```

Beim Vergleich fällt schnell auf, dass Gamma- und Weibullverteilungen die genausten Modelle sind. Gewählt wird hier die Gammaverteilung, da diese sowohl der Empfehlung von UnivariateML entspricht als auch die unteren Quantile im Vergleich besser abdeckt.


\newpage

# Simulation

## Generieren

```{r}
amount_iteration <- 1e5
```

Das Generieren der Daten wurde in R umgesetzt. Dabei wurden die gewählten Verteilungen gewählt, welche im Kapitel [Verteilungen](#Verteilungen) gewählt wurden. Es wurde sich dafür entschieden die Anzahl Steinschläge auf **`r amount_iteration`** Interation festzulegen.

```{r}
#| echo: true
set.seed(8128) # The 4. perfect number
zone_1_generated = data.frame(
  mass = runif(amount_iteration, min=0, max=1),
  velocity = runif(amount_iteration, min=0, max=1),
  time_diff = runif(amount_iteration, min=0, max=1)
)

zone_2_generated = data.frame(
  mass = runif(amount_iteration, min=0, max=1),
  velocity = runif(amount_iteration, min=0, max=1),
  time_diff = runif(amount_iteration, min=0, max=1)
)
```

Die Kinetische Energie wird anhand der Geschwindigkeit und Masse eines Steinschlags, mittels der Physikalischen Formel dafür berechnet und in Kilo Newton Meter umgewandelt.

$$
E_{\text{kin}} = \frac{1}{2} \times m \times v^{2}
$$\newline

```{r}
#| echo: true

zone_1_generated$kin_energy = 
  zone_1_generated$mass * zone_1_generated$velocity^2 * 0.5 / 1000

zone_2_generated$kin_energy = 
  zone_2_generated$mass * zone_2_generated$velocity^2 * 0.5 / 1000
```

// TODO: Show Plots with densetiy: ExtraGrid \newpage

## Wahrscheinlichkeitsberechnung

Dass bei einem Steinschlag die Sicherheitsnetze reissen, müsste die kinetische Energie höher sein als 1200 kNm oder 600 kNm und die Masse im Sicherheitsnetz grösser oder gleich 2000 kg sein. Das Sicherheitsnetz wird alle 24 Stunden geleert.

Um die Masse im Netz bei einem Steinschlag zu berechnen, wird rekursiv durch alle vergangenen Steinschläge, welche in den letzten 24 Stunden stattgefunden haben, gegangen und die Masse summiert. Dadurch wird es ermöglicht, alle Steinschläge herauszufiltern, welche eine kinetische Energie von mindestens 1200 kNm haben oder mindestens 600 kNm und im Sicherheitsnetz eine Gesamtmasse von 2000 kg liegen.

Mit diesen Angaben ist es möglich, die Wahrscheinlichkeit, dass das Sicherheitsnetz reisst, auszurechnen. Dafür verwenden wir folgende Formel.

$$
P_{\text{Netz reisst}} = \frac{\text{Anzahl Netz Versagen}}{\text{Anzahl Steinschläge}} 
$$

Das ein Steinschlag in einem Unfall endet muss zusätzlich ein Auto vor Ort sein. Um die Wahrscheinlichkeit zu berechnen wird die Zeit Benötigt, welches ein Auto braucht um für einen Möglichen Steinschlag zu bremsen. Dies lässt sich aus dem Bremsweg, was sich bei einer [Gefahrenbesmung bei 18m](https://www.adac.de/verkehr/rund-um-den-fuehrerschein/erwerb/anhalteweg-berechnen/) liegt, bei einer Geschwindigkeit von 60 km/h und der Geschwindigkeit, wie folgt berechnen.

$$
t = \frac{2s}{v} \Rightarrow \frac{2\times18m}{16.\overline{6}m/s} \approx 2.16s 
$$

Dazu wird noch die [Vorbremszeit von 1.2 Sekunde](https://www.adac.de/verkehr/rund-um-den-fuehrerschein/erwerb/reaktionsweg-berechnen/) addiert, welche ein Mensch braucht um auf die Bremse zu drücken. Damit kommt man auf *3.36 Sekunden*, welche ein Auto in der Gefahrenzone ist. Durch diesen Wert können wir die Wahrscheinlichkeit berechnen, dass ein Auto zu einem beliebigen Zeitpunkt in der Gefahrenzone ist.

$$
P_{\text{Auto anwesend}} = \frac{3.36 \times \text{Anazhl Autos Pro Tag}}{\text{Anzahl Sekunden Pro Tag}} \Rightarrow \frac{3.36 \times 600}{86400} = \frac{7}{300}
$$

Mit der Wahrscheinlichkeit, dass das Sicherheitsnetz reisst, ein Auto anwesend ist und der durchschnittlichen Steinschläge pro Jahr, lässt sich die Wahrscheinlichkeit eines tödlichen Unfalls in einer Zone für ein Jahr berechnen.

$$
P_{\text{Tödlicher Unfall pro Jahr}} = P_{\text{Auto anwesend}} \times P_{\text{Netz reisst}} \times \text{ Durchschnittliche Steinschläge pro Jahr}
$$

## Aussagekraft der Simulation

// TODO: mit Varianz und so. Könnte noch triky werden.

\newpage

# Ergebniss

\newpage

# Empfehlung
